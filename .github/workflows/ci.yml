name: CI

on:
  push:
    branches: [ main, integration/** ]
  pull_request:
    branches: [ main, integration/** ]

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  python-tests-unit:
    name: Python Unit Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r dashboard_api/requirements.txt
          pip install -r metadata_watcher/requirements.txt
          pip install -r track_mapper/requirements.txt
          pip install pytest
      - name: Run unit tests
        run: |
          pytest -q tests/unit

  ui-lint-build:
    name: UI Lint & Build
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: dashboard
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: dashboard/package-lock.json
      - name: Install deps
        run: npm ci
      - name: Lint
        run: npm run lint
      - name: Build
        run: npm run build

name: CI

on:
  push:
    branches: [ main, integration/** ]
  pull_request:
    branches: [ main, integration/** ]

permissions:
  contents: read

env:
  PIP_CACHE_DIR: ./.pip-cache

jobs:
  python-checks:
    name: Python Lint + Type Check (${{ matrix.service }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        service: [ dashboard_api, metadata_watcher, track_mapper ]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ${{ env.PIP_CACHE_DIR }}
          key: ${{ runner.os }}-pip-${{ hashFiles(matrix.service + '/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install deps + tooling
        run: |
          python -m pip install --upgrade pip
          if [ -f "${{ matrix.service }}/requirements.txt" ]; then pip install -r "${{ matrix.service }}/requirements.txt"; fi
          pip install ruff black isort mypy

      - name: Ruff (lint)
        run: ruff check ${{ matrix.service }}

      - name: Black (format check)
        run: black --check ${{ matrix.service }}

      - name: isort (imports)
        run: isort --check-only ${{ matrix.service }}

      - name: mypy (types)
        run: mypy --ignore-missing-imports ${{ matrix.service }}

  node-ui:
    name: Dashboard UI Build + Lint
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: dashboard
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: dashboard/package-lock.json
      - name: Install
        run: npm ci
      - name: Lint (if configured)
        run: |
          if jq -e '.scripts.lint' package.json >/dev/null 2>&1; then npm run lint; else echo "no lint script"; fi
      - name: Build
        run: npm run build

  docker-validate:
    name: Docker Build Validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Validate docker compose config
        run: docker compose -f docker-compose.yml config
      - name: Build dashboard-api
        run: docker build -t test-dashboard-api -f dashboard_api/Dockerfile dashboard_api
      - name: Build metadata-watcher
        run: docker build -t test-metadata-watcher -f metadata_watcher/Dockerfile .
      - name: Build nginx-rtmp
        run: docker build -t test-nginx-rtmp -f nginx-rtmp/Dockerfile nginx-rtmp
      - name: Build dashboard-ui
        run: docker build -t test-dashboard-ui -f dashboard/Dockerfile dashboard

  compose-integration:
    name: Compose Integration Boot
    runs-on: ubuntu-latest
    # Run independently so builds validate even if linters fail
    steps:
      - uses: actions/checkout@v4

      - name: Install ffmpeg and curl
        run: sudo apt-get update && sudo apt-get install -y ffmpeg curl jq

      - name: Start compose
        env:
          POSTGRES_USER: radio
          POSTGRES_PASSWORD: radio_password
          POSTGRES_DB: radio_db
          API_TOKEN: ci-internal-token
          JWT_SECRET: ci-jwt-secret
          AZURACAST_URL: http://localhost
          AZURACAST_API_KEY: dummy
          AZURACAST_AUDIO_URL: http://ice1.somafm.com/groovesalad-128-mp3
          LOG_LEVEL: INFO
          DEBUG: 'false'
          ENVIRONMENT: ci
        run: |
          docker compose -f docker-compose.yml up -d --build
          echo "Waiting for services..."
          for i in $(seq 1 60); do
            DASH=$(curl -sf http://localhost:9001/health || true)
            WATCH=$(curl -sf http://localhost:9000/health || true)
            PROM=$(curl -sf http://localhost:9090/-/healthy || true)
            if echo "$DASH" | grep -q '"status"\s*:\s*"healthy"' && [ -n "$WATCH" ] && echo "$PROM" | grep -q 'OK'; then
              echo "Services are healthy"; break; fi
            sleep 2
            if [ $i -eq 60 ]; then echo "Timeout waiting for services"; docker compose ps; exit 1; fi
          done
          curl -sf http://localhost:9001/health | jq .
          curl -sf http://localhost:9000/health | jq .

      - name: Exercise minimal flow (login + export config)
        run: |
          ACCESS=$(curl -sf -H 'Content-Type: application/json' -d '{"username":"admin","password":"admin123"}' http://localhost:9001/api/v1/auth/login | jq -r .access_token)
          test -n "$ACCESS"
          curl -sf -H "Authorization: Bearer ci-internal-token" http://localhost:9001/api/v1/config/internal/export | head -c 200

      - name: Tear down
        if: always()
        run: docker compose -f docker-compose.yml down -v

  security:
    name: Security (pip-audit / npm audit)
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: pip-audit
        run: |
          python -m pip install --upgrade pip pip-audit || true
          for req in dashboard_api/requirements.txt metadata_watcher/requirements.txt track_mapper/requirements.txt; do
            [ -f "$req" ] && pip-audit -r "$req" || true;
          done
      - name: npm audit
        working-directory: dashboard
        run: |
          npm ci || true
          npm audit --omit=dev || true

name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: read
  security-events: write  # For uploading SARIF results
  actions: read

env:
  PYTHON_VERSION: '3.11'
  POSTGRES_VERSION: '15'

jobs:
  # Linting and code quality checks
  lint:
    name: Lint and Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run Black (formatting check)
      run: |
        black --check --line-length 100 .
    
    - name: Run Flake8 (linting)
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics \
          --exclude=venv,.venv,env,.env,node_modules,.git,__pycache__,.pytest_cache,htmlcov
        flake8 . --count --max-complexity=10 --max-line-length=100 --statistics \
          --exclude=venv,.venv,env,.env,node_modules,.git,__pycache__,.pytest_cache,htmlcov
    
    - name: Run mypy (type checking)
      run: |
        mypy --install-types --non-interactive --ignore-missing-imports .
      continue-on-error: true  # Don't fail build on type errors yet

  # Unit tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --tb=short --junitxml=junit/test-results-unit.xml
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-test-results
        path: junit/test-results-unit.xml

  # Integration tests with Docker
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: test_radio
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_radio_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Set up database schema
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: test_radio
        POSTGRES_PASSWORD: test_password
        POSTGRES_DB: test_radio_db
      run: |
        PGPASSWORD=test_password psql -h localhost -U test_radio -d test_radio_db -f track_mapper/schema.sql || true
        PGPASSWORD=test_password psql -h localhost -U test_radio -d test_radio_db -f logging_module/schema.sql || true
    
    - name: Generate test video fixtures
      run: |
        python tests/fixtures/generate_test_video.py || echo "Test video generation skipped (FFmpeg may not be available)"
    
    - name: Run integration tests
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: test_radio
        POSTGRES_PASSWORD: test_password
        POSTGRES_DB: test_radio_db
        ENVIRONMENT: test
      run: |
        pytest tests/integration/ -v --tb=short -m "not requires_docker" --junitxml=junit/test-results-integration.xml
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: junit/test-results-integration.xml

  # Coverage report
  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: test_radio
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_radio_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run tests with coverage
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: test_radio
        POSTGRES_PASSWORD: test_password
        POSTGRES_DB: test_radio_db
        ENVIRONMENT: test
      run: |
        pytest tests/unit/ tests/integration/ \
          -m "not requires_docker and not slow" \
          --cov=. \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing
    
    - name: Check coverage threshold
      run: |
        coverage report --fail-under=80
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
    
    - name: Upload coverage HTML
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-report
        path: htmlcov/

  # Docker build test
  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Build metadata-watcher image
      uses: docker/build-push-action@v4
      with:
        context: ./metadata_watcher
        file: ./metadata_watcher/Dockerfile
        push: false
        tags: liveradio-metadata-watcher:test
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Test docker-compose configuration
      run: |
        docker compose -f docker-compose.test.yml config

  # Load tests (only on main branch or manual trigger)
  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    needs: [unit-tests, integration-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Start test services
      run: |
        docker compose -f docker-compose.test.yml up -d
        sleep 30  # Wait for services to be ready
    
    - name: Run load tests
      run: |
        locust -f tests/load/locustfile.py \
          --host=http://localhost:9001 \
          --users 10 \
          --spawn-rate 2 \
          --run-time 2m \
          --headless \
          --only-summary \
          --html=locust_report.html
    
    - name: Upload load test report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: load-test-report
        path: locust_report.html
    
    - name: Stop test services
      if: always()
      run: |
        docker compose -f docker-compose.test.yml down -v

  # Security scan
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy results to GitHub Security
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  # Final status check
  status:
    name: CI Status
    runs-on: ubuntu-latest
    needs: [lint, unit-tests, integration-tests, coverage, docker-build]
    if: always()
    
    steps:
    - name: Check job statuses
      run: |
        echo "Lint: ${{ needs.lint.result }}"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Coverage: ${{ needs.coverage.result }}"
        echo "Docker Build: ${{ needs.docker-build.result }}"
        
        if [[ "${{ needs.lint.result }}" != "success" ]] || \
           [[ "${{ needs.unit-tests.result }}" != "success" ]] || \
           [[ "${{ needs.integration-tests.result }}" != "success" ]] || \
           [[ "${{ needs.coverage.result }}" != "success" ]] || \
           [[ "${{ needs.docker-build.result }}" != "success" ]]; then
          echo "❌ CI pipeline failed"
          exit 1
        else
          echo "✅ All CI checks passed"
        fi



