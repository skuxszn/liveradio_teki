name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: read
  security-events: write  # For uploading SARIF results
  actions: read

env:
  PYTHON_VERSION: '3.11'
  POSTGRES_VERSION: '15'

jobs:
  # Linting and code quality checks
  lint:
    name: Lint and Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run Black (formatting check)
      run: |
        black --check --line-length 100 .
    
    - name: Run Flake8 (linting)
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics \
          --exclude=venv,.venv,env,.env,node_modules,.git,__pycache__,.pytest_cache,htmlcov
        flake8 . --count --max-complexity=10 --max-line-length=100 --statistics \
          --exclude=venv,.venv,env,.env,node_modules,.git,__pycache__,.pytest_cache,htmlcov
    
    - name: Run mypy (type checking)
      run: |
        mypy --install-types --non-interactive --ignore-missing-imports .
      continue-on-error: true  # Don't fail build on type errors yet

  # Unit tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --tb=short --junitxml=junit/test-results-unit.xml
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-test-results
        path: junit/test-results-unit.xml

  # Integration tests with Docker
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: test_radio
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_radio_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Set up database schema
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: test_radio
        POSTGRES_PASSWORD: test_password
        POSTGRES_DB: test_radio_db
      run: |
        PGPASSWORD=test_password psql -h localhost -U test_radio -d test_radio_db -f track_mapper/schema.sql || true
        PGPASSWORD=test_password psql -h localhost -U test_radio -d test_radio_db -f logging_module/schema.sql || true
    
    - name: Generate test video fixtures
      run: |
        python tests/fixtures/generate_test_video.py || echo "Test video generation skipped (FFmpeg may not be available)"
    
    - name: Run integration tests
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: test_radio
        POSTGRES_PASSWORD: test_password
        POSTGRES_DB: test_radio_db
        ENVIRONMENT: test
      run: |
        pytest tests/integration/ -v --tb=short -m "not requires_docker" --junitxml=junit/test-results-integration.xml
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: junit/test-results-integration.xml

  # Coverage report
  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: test_radio
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_radio_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run tests with coverage
      env:
        POSTGRES_HOST: localhost
        POSTGRES_PORT: 5432
        POSTGRES_USER: test_radio
        POSTGRES_PASSWORD: test_password
        POSTGRES_DB: test_radio_db
        ENVIRONMENT: test
      run: |
        pytest tests/unit/ tests/integration/ \
          -m "not requires_docker and not slow" \
          --cov=. \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing
    
    - name: Check coverage threshold
      run: |
        coverage report --fail-under=80
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
    
    - name: Upload coverage HTML
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-report
        path: htmlcov/

  # Docker build test
  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Build metadata-watcher image
      uses: docker/build-push-action@v4
      with:
        context: ./metadata_watcher
        file: ./metadata_watcher/Dockerfile
        push: false
        tags: liveradio-metadata-watcher:test
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Test docker-compose configuration
      run: |
        docker compose -f docker-compose.test.yml config

  # Load tests (only on main branch or manual trigger)
  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    needs: [unit-tests, integration-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Start test services
      run: |
        docker compose -f docker-compose.test.yml up -d
        sleep 30  # Wait for services to be ready
    
    - name: Run load tests
      run: |
        locust -f tests/load/locustfile.py \
          --host=http://localhost:9001 \
          --users 10 \
          --spawn-rate 2 \
          --run-time 2m \
          --headless \
          --only-summary \
          --html=locust_report.html
    
    - name: Upload load test report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: load-test-report
        path: locust_report.html
    
    - name: Stop test services
      if: always()
      run: |
        docker compose -f docker-compose.test.yml down -v

  # Security scan
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy results to GitHub Security
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  # Final status check
  status:
    name: CI Status
    runs-on: ubuntu-latest
    needs: [lint, unit-tests, integration-tests, coverage, docker-build]
    if: always()
    
    steps:
    - name: Check job statuses
      run: |
        echo "Lint: ${{ needs.lint.result }}"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Coverage: ${{ needs.coverage.result }}"
        echo "Docker Build: ${{ needs.docker-build.result }}"
        
        if [[ "${{ needs.lint.result }}" != "success" ]] || \
           [[ "${{ needs.unit-tests.result }}" != "success" ]] || \
           [[ "${{ needs.integration-tests.result }}" != "success" ]] || \
           [[ "${{ needs.coverage.result }}" != "success" ]] || \
           [[ "${{ needs.docker-build.result }}" != "success" ]]; then
          echo "❌ CI pipeline failed"
          exit 1
        else
          echo "✅ All CI checks passed"
        fi



